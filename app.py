# app.py - SAPZAP downloader (Fixed YouTube and Instagram issues)
import os
import re
import uuid
import random
import tempfile
import shutil
import logging
import time
import sys
import subprocess
from flask import Flask, request, render_template, Response, jsonify
from config import INSTAGRAM_COOKIES, YOUTUBE_COOKIES, YT_PO_TOKEN
import yt_dlp
from yt_dlp.utils import DownloadError

app = Flask(__name__)

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# Useful constants and UA lists
MOBILE_USER_AGENTS = [
    'Mozilla/5.0 (iPhone; CPU iPhone OS 17_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1',
    'Mozilla/5.0 (Linux; Android 14; SM-S908B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Mobile Safari/537.36',
    'Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1',
    'Mozilla/5.0 (Linux; Android 14; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Mobile Safari/537.36',
]
DESKTOP_USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
]

YOUTUBE_REGEX = re.compile(r'(?:youtube\.com/(?:watch\?v=|shorts/)|youtu\.be/)([a-zA-Z0-9_-]{11})')

def get_video_id_from_url(url):
    m = YOUTUBE_REGEX.search(url)
    return m.group(1) if m else None

def is_shorts_url(url):
    return '/shorts/' in url or 'youtube.com/shorts' in url or 'youtu.be/' in url

def create_cookies_file(cookies_dict, domain='.youtube.com'):
    """Write a simple Netscape cookiejar file from a dict of name->value. Returns path or None."""
    if not cookies_dict or not any(cookies_dict.values()):
        return None
    try:
        with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt') as tf:
            tf.write("# Netscape HTTP Cookie File\n# Generated by SAPZAP\n\n")
            count = 0
            for name, value in cookies_dict.items():
                if value and str(value).strip():
                    expiry = str(int(time.time()) + 31536000)
                    tf.write(f"{domain}\tTRUE\t/\tTRUE\t{expiry}\t{name}\t{value}\n")
                    count += 1
            logger.info(f"Created cookies file with {count} cookies")
            return tf.name
    except Exception as e:
        logger.warning(f"Failed to create cookies file: {e}")
        return None

def normalize_po_token(candidate):
    """
    Try to normalize common PO token formats into the form expected by yt-dlp.
    Return None if invalid.
    """
    if not candidate:
        return None
    s = str(candidate).strip()
    # Check if it's already in correct format (client.context+token)
    if re.match(r'^[a-zA-Z]+\.[a-zA-Z]+\+[A-Z0-9]+$', s):
        return s
    return None

def clean_filename(title, resolution=None, ext='mp4', video_id=None):
    if not title or not title.strip():
        base = f"sapzap_{uuid.uuid4().hex[:8]}"
    else:
        clean = re.sub(r'[^\w\s-]', '', title).strip()
        clean = re.sub(r'[-\s]+', '_', clean)
        base = f"sapzap_{clean[:50]}"
    if video_id:
        base = f"{base}_{video_id}"
    return f"{base}_{resolution}p.{ext}" if resolution else f"{base}.{ext}"

def extract_height_from_info(info):
    if not info:
        return None
    # prefer direct height
    if info.get('height'):
        return info.get('height')
    # requested_formats may contain heights
    rf = info.get('requested_formats') or info.get('formats') or []
    heights = [f.get('height') for f in rf if f.get('height')]
    return max(heights) if heights else None

def download_with_config(url, config):
    """Download using the supplied config and return info dict (ydl.extract_info will download)."""
    with yt_dlp.YoutubeDL(config) as ydl:
        info = ydl.extract_info(url, download=True)
        return info

def check_resolution_requirements(info, is_shorts):
    """
    Check if the downloaded content meets resolution requirements.
    """
    height = extract_height_from_info(info)
    if not height:
        logger.warning("Could not determine video height")
        return False
    
    if is_shorts:
        if height < 1080:
            logger.warning(f"Shorts/Reels resolution {height}p is below required 1080p")
            return False
    else:
        if height < 720:
            logger.warning(f"Video resolution {height}p is below required 720p")
            return False
    
    logger.info(f"Video meets resolution requirements: {height}p")
    return True

def get_youtube_cookies():
    """Get YouTube cookies file path or create one if needed"""
    if not YOUTUBE_COOKIES or not any(YOUTUBE_COOKIES.values()):
        return None
        
    cookie_path = create_cookies_file(YOUTUBE_COOKIES, domain='.youtube.com')
    if cookie_path:
        logger.info("Created YouTube cookies file")
    return cookie_path

def get_instagram_cookies():
    """Get Instagram cookies file path or create one if needed"""
    if not INSTAGRAM_COOKIES or not any(INSTAGRAM_COOKIES.values()):
        return None
        
    cookie_path = create_cookies_file(INSTAGRAM_COOKIES, domain='.instagram.com')
    if cookie_path:
        logger.info("Created Instagram cookies file")
    return cookie_path

def download_youtube_video(url, temp_dir, prefer_merge=False):
    """
    Download YouTube video with improved configuration
    """
    video_id = get_video_id_from_url(url)
    is_shorts = is_shorts_url(url)
    if not video_id:
        raise ValueError("Invalid YouTube URL")

    logger.info(f"Downloading YouTube video: {video_id} (prefer_merge={prefer_merge})")

    # Check if ffmpeg is available for merging
    ffmpeg_available = False
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        ffmpeg_available = True
        logger.info("FFmpeg is available for merging")
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("FFmpeg is not available, will use combined formats only")
        prefer_merge = False

    # Get cookies if available
    youtube_cookies = get_youtube_cookies()
    
    # Base config
    base_config = {
        'outtmpl': f'{temp_dir}/%(title)s.%(ext)s',
        'socket_timeout': 30,
        'retries': 3,
        'fragment_retries': 3,
        'noplaylist': True,
        'no_warnings': False,
        'quiet': False,
        'logger': logger,
        'no_check_certificate': True,
    }
    
    # Add cookies if available
    if youtube_cookies:
        base_config['cookiefile'] = youtube_cookies

    # Add PO token if available
    po_token = normalize_po_token(YT_PO_TOKEN)
    if po_token:
        base_config['extractor_args'] = {
            'youtube': {
                'player_client': ['android', 'web'],
                'player_skip': ['configs', 'webpage']
            }
        }

    # Define format selectors based on content type
    if is_shorts:
        # For Shorts, prioritize higher resolutions
        if prefer_merge and ffmpeg_available:
            selectors = [
                'bestvideo[height>=1080][ext=mp4]+bestaudio[ext=m4a]/best[height>=1080][ext=mp4]/best[ext=mp4]',
                'bestvideo[height>=720][ext=mp4]+bestaudio[ext=m4a]/best[height>=720][ext=mp4]/best[ext=mp4]',
                'best[ext=mp4]'
            ]
        else:
            selectors = [
                'best[height>=1080][ext=mp4]/best[height>=720][ext=mp4]/best[ext=mp4]',
                'best[ext=mp4]'
            ]
    else:
        # For regular videos, cap at 1080p
        if prefer_merge and ffmpeg_available:
            selectors = [
                'bestvideo[height<=1080][ext=mp4]+bestaudio[ext=m4a]/best[height<=1080][ext=mp4]/best[height>=720][ext=mp4]',
                'best[height<=1080][ext=mp4]/best[height>=720][ext=mp4]',
                'best[ext=mp4]'
            ]
        else:
            selectors = [
                'best[height<=1080][ext=mp4]/best[height>=720][ext=mp4]',
                'best[ext=mp4]'
            ]

    last_err = None
    for i, selector in enumerate(selectors):
        try:
            config = dict(base_config)
            config['format'] = selector
            config['http_headers'] = {
                'User-Agent': random.choice(DESKTOP_USER_AGENTS),
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Referer': 'https://www.youtube.com/',
            }

            logger.info(f"Attempt {i+1} with selector: {selector}")
            info = download_with_config(url, config)

            # Check if resolution meets requirements
            if not check_resolution_requirements(info, is_shorts):
                logger.warning(f"Downloaded video does not meet resolution requirements, trying next selector")
                continue

            # Success
            height = extract_height_from_info(info)
            info['_final_height'] = height
            logger.info(f"SUCCESS: Downloaded at {height}p with selector: {selector}")
            
            # Clean up cookies file
            if youtube_cookies and os.path.exists(youtube_cookies):
                try:
                    os.unlink(youtube_cookies)
                except:
                    pass
                    
            return info, video_id, is_shorts

        except Exception as e:
            last_err = e
            logger.warning(f"Attempt {i+1} with selector '{selector}' failed: {e}")
            # Small delay before next attempt
            time.sleep(1)

    # Clean up cookies file if still exists
    if youtube_cookies and os.path.exists(youtube_cookies):
        try:
            os.unlink(youtube_cookies)
        except:
            pass

    # All attempts failed
    if last_err:
        raise last_err
    raise RuntimeError("All YouTube download attempts failed")

def download_instagram_reel(url, temp_dir):
    """
    Download an Instagram reel with retry logic for consistent quality.
    """
    logger.info("Downloading Instagram reel - selecting highest quality")
    
    # Get cookies if available
    instagram_cookies = get_instagram_cookies()
    
    base_config = {
        'outtmpl': f'{temp_dir}/%(title)s.%(ext)s',
        'socket_timeout': 20,
        'retries': 3,
        'noplaylist': True,
        'logger': logger,
        'no_check_certificate': True,
    }
    
    # Add cookies if available
    if instagram_cookies:
        base_config['cookiefile'] = instagram_cookies

    # Try to get the highest resolution available
    selectors = [
        'bestvideo[height<=1920][ext=mp4]+bestaudio[ext=m4a]/best[height<=1920][ext=mp4]',  # Try merged first
        'best[height<=1920][ext=mp4]',  # Fallback to best combined
    ]

    last_err = None
    max_retries = 3
    
    for sel in selectors:
        for attempt in range(max_retries):
            try:
                cfg = dict(base_config)
                cfg['format'] = sel
                cfg['http_headers'] = {
                    'User-Agent': random.choice(MOBILE_USER_AGENTS),
                    'Referer': 'https://www.instagram.com/',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Accept-Encoding': 'gzip, deflate',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                }
                
                with yt_dlp.YoutubeDL(cfg) as ydl:
                    info = ydl.extract_info(url, download=True)
                    height = extract_height_from_info(info)
                    
                    # Check if resolution meets requirements (minimum 1080p for Reels)
                    if height and height < 1080:
                        logger.warning(f"Instagram Reel resolution {height}p is below required 1080p, trying next selector")
                        continue
                        
                    info['_final_height'] = height
                    logger.info(f"Instagram download succeeded (selector={sel}) - height={height}")
                    
                    # Clean up cookies file
                    if instagram_cookies and os.path.exists(instagram_cookies):
                        try:
                            os.unlink(instagram_cookies)
                        except:
                            pass
                            
                    return info, None, True
            except Exception as e:
                last_err = e
                logger.warning(f"Instagram selector {sel} attempt {attempt+1} failed: {e}")
                
                # Wait before retry
                if attempt < max_retries - 1:
                    wait_time = (2 ** attempt) + random.random()
                    time.sleep(wait_time)
                continue

    # Clean up cookies file if still exists
    if instagram_cookies and os.path.exists(instagram_cookies):
        try:
            os.unlink(instagram_cookies)
        except:
            pass

    if last_err:
        raise last_err
    raise RuntimeError("Instagram download failed after all retries")

def download_media(url, platform_hint=None, prefer_merge=False):
    """
    Master function - chooses between youtube and instagram based on platform_hint
    or auto-detect from url.
    """
    url = url.strip()
    temp_dir = tempfile.mkdtemp(prefix='sapzap_')
    try:
        logger.info(f"Processing URL: {url} platform_hint={platform_hint} prefer_merge={prefer_merge}")

        # determine platform
        if platform_hint:
            platform = platform_hint.lower()
        else:
            if 'instagram.com/' in url:
                platform = 'instagram'
            elif 'youtube.com' in url or 'youtu.be' in url:
                platform = 'youtube'
            else:
                raise ValueError("Unsupported URL. Only YouTube and Instagram supported.")

        if platform == 'instagram':
            info, video_id, is_shorts = download_instagram_reel(url, temp_dir)
        else:
            # youtube path
            info, video_id, is_shorts = download_youtube_video(url, temp_dir, prefer_merge=prefer_merge)

        # find downloaded file in temp_dir
        files = [f for f in os.listdir(temp_dir) if f.lower().endswith(('.mp4', '.mkv', '.webm', '.mov', '.m4a'))]
        if not files:
            raise RuntimeError("Download completed but no file was found in temp directory")
        # pick first file (yt-dlp outputs single file in most successful cases)
        file_path = os.path.join(temp_dir, files[0])

        title = info.get('title', 'unknown')
        height = info.get('_final_height') or extract_height_from_info(info) or 'unknown'
        # ensure height is string/number
        try:
            height_int = int(height) if isinstance(height, (int, float, str)) and str(height).isdigit() else height
        except:
            height_int = height

        # create friendly filename
        if video_id:
            filename = clean_filename(title, resolution=height_int, ext='mp4', video_id=video_id)
        else:
            filename = clean_filename(title, resolution=height_int, ext='mp4', video_id=uuid.uuid4().hex[:8])

        logger.info(f"Prepared file: {filename} (path: {file_path})")
        return file_path, filename, temp_dir

    except Exception:
        # cleanup on error
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir, ignore_errors=True)
            except:
                pass
        raise

# Flask routes
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/download', methods=['POST'])
def download():
    url = request.form.get('url') or request.values.get('url') or ''
    platform = request.form.get('platform') or request.values.get('platform') or ''
    force_merge = bool(request.form.get('force_merge') or request.values.get('force_merge'))
    url = url.strip()
    if not url:
        return "URL is required.", 400

    # convert platform empty string to None for auto-detect
    platform_hint = platform.strip().lower() if platform and platform.strip() else None

    try:
        # Call master download
        file_path, filename, temp_dir = download_media(url, platform_hint=platform_hint, prefer_merge=force_merge)

        # Stream file back
        def generate():
            try:
                with open(file_path, 'rb') as f:
                    while True:
                        chunk = f.read(512 * 1024)
                        if not chunk:
                            break
                        yield chunk
            finally:
                # cleanup after streaming
                if temp_dir and os.path.exists(temp_dir):
                    try:
                        shutil.rmtree(temp_dir, ignore_errors=True)
                        logger.info("Temporary files cleaned up")
                    except Exception as e:
                        logger.warning(f"Failed to remove temp dir: {e}")

        ext = os.path.splitext(filename)[1][1:].lower()
        mime_types = {'mp4': 'video/mp4', 'webm': 'video/webm', 'mkv': 'video/x-matroska', 'mov': 'video/quicktime', 'm4a': 'audio/mp4'}
        mime = mime_types.get(ext, 'application/octet-stream')

        headers = {
            'Content-Disposition': f'attachment; filename="{filename}"',
            'Content-Type': mime,
            'Cache-Control': 'no-cache',
            'Connection': 'close',
        }

        return Response(generate(), mimetype=mime, headers=headers)

    except ValueError as ve:
        logger.warning(f"Download failed (client): {ve}")
        return str(ve), 400
    except Exception as e:
        logger.error(f"Critical error during download: {e}", exc_info=True)
        return "A server error occurred. Check server logs for details.", 500

@app.route('/health')
def health():
    yt_cookies_count = len([v for v in YOUTUBE_COOKIES.values() if v]) if YOUTUBE_COOKIES else 0
    ig_cookies_count = len([v for v in INSTAGRAM_COOKIES.values() if v]) if INSTAGRAM_COOKIES else 0
    po_token_norm = normalize_po_token(YT_PO_TOKEN)
    return {
        'status': 'healthy',
        'yt_dlp_version': yt_dlp.version.__version__,
        'youtube_cookies_configured': yt_cookies_count,
        'instagram_cookies_configured': ig_cookies_count,
        'po_token': 'valid' if po_token_norm else 'invalid_or_missing',
        'note': 'If YouTube returns "content not available on this app", try updating cookies/PO token or enable force merge (requires server ffmpeg).'
    }, 200

if __name__ == '__main__':
    print("\n🎬 SAPZAP - Smart Resolution Downloader")
    print(f"yt-dlp version: {yt_dlp.version.__version__}")
    po_token_norm = normalize_po_token(YT_PO_TOKEN)
    print(f"PO token: {'VALID' if po_token_norm else 'INVALID or MISSING'}")
    # Check if ffmpeg is available
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        print("FFmpeg: AVAILABLE (merge supported)")
    except (subprocess.SubprocessError, FileNotFoundError):
        print("FFmpeg: NOT AVAILABLE (merge not supported)")
    print("Starting server...")
    app.run(debug=False, host='0.0.0.0', port=int(os.environ.get('PORT', 5000)))

    